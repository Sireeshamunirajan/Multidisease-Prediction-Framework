{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection & Preprocessing Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured Data (Diabetes, Heart, Kidney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing diabetes dataset...\n",
      "diabetes dataset processed and scaler saved at models/diabetes_scaler.pkl\n",
      "Processing heart dataset...\n",
      "heart dataset processed and scaler saved at models/heart_scaler.pkl\n",
      "Processing kidney dataset...\n",
      "kidney dataset processed and scaler saved at models/kidney_scaler.pkl\n",
      "All structured datasets processed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Ensure the models directory exists\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "\n",
    "# Define dataset paths\n",
    "datasets = {\n",
    "    \"diabetes\": \"datasets/diabetes.csv\",\n",
    "    \"heart\": \"datasets/heart.csv\",\n",
    "    \"kidney\": \"datasets/kidney.csv\"\n",
    "}\n",
    "\n",
    "processed_data = {}\n",
    "\n",
    "for disease, path in datasets.items():\n",
    "    print(f\"Processing {disease} dataset...\")\n",
    "\n",
    "    # Load dataset\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: {path} not found!\")\n",
    "        continue  # Skip if file doesn't exist\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Convert categorical text columns to numeric values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # If column contains text\n",
    "            df[col] = df[col].astype(str)  # Ensure all values are strings\n",
    "            df[col] = LabelEncoder().fit_transform(df[col])  # Convert to numeric\n",
    "\n",
    "    # Convert all non-numeric data to NaN and handle missing values\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    df.fillna(df.mean(), inplace=True)  # Fill NaN with column mean\n",
    "\n",
    "    # Verify if any column still contains non-numeric values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            print(f\"Error: Column {col} in {disease} dataset is still non-numeric!\")\n",
    "            print(df[col].unique())  # Print unique values for debugging\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.iloc[:, :-1]  # All columns except last one\n",
    "    y = df.iloc[:, -1]   # Last column (target)\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Save processed data\n",
    "    processed_data[disease] = (X_scaled, y)\n",
    "\n",
    "    # Save the scaler\n",
    "    scaler_path = f\"models/{disease}_scaler.pkl\"\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "\n",
    "    print(f\"{disease} dataset processed and scaler saved at {scaler_path}\")\n",
    "\n",
    "print(\"All structured datasets processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load and Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(path, img_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Load images from the dataset directory, resize them, normalize pixel values, and return arrays.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the image dataset folder.\n",
    "        img_size (tuple): Target size for resizing images (default: 128x128).\n",
    "\n",
    "    Returns:\n",
    "        np.array: Processed image data.\n",
    "        np.array: Corresponding labels.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: Directory '{path}' does not exist!\")\n",
    "        return np.array(data), np.array(labels)\n",
    "\n",
    "    for label in os.listdir(path):\n",
    "        label_path = os.path.join(path, label)\n",
    "        if not os.path.isdir(label_path):  # Ensure it's a folder\n",
    "            continue\n",
    "\n",
    "        for img_name in os.listdir(label_path):\n",
    "            img_path = os.path.join(label_path, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "            \n",
    "            if img is None:  # Skip unreadable images\n",
    "                print(f\"Warning: Unable to read {img_path}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.resize(img, img_size)  # Resize image\n",
    "            img = img / 255.0  # Normalize pixel values to [0,1]\n",
    "            \n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed_data(X, y, disease_name):\n",
    "    \"\"\"\n",
    "    Save processed image data and labels as NumPy arrays.\n",
    "\n",
    "    Args:\n",
    "        X (numpy array): Processed image data.\n",
    "        y (numpy array): Corresponding labels.\n",
    "        disease_name (str): Name of the disease dataset.\n",
    "    \"\"\"\n",
    "    np.save(f\"datasets/{disease_name}_data.npy\", X)\n",
    "    np.save(f\"datasets/{disease_name}_labels.npy\", y)\n",
    "    print(f\"{disease_name} dataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Run the Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malaria dataset saved successfully!\n",
      "Warning: Unable to read datasets/pneumonia/Normal\\Pneumonia, skipping...\n",
      "pneumonia dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Process Malaria Dataset\n",
    "malaria_data, malaria_labels = load_and_preprocess_images(\"datasets/malaria/\")\n",
    "save_preprocessed_data(malaria_data, malaria_labels, \"malaria\")\n",
    "\n",
    "# Process Pneumonia Dataset\n",
    "pneumonia_data, pneumonia_labels = load_and_preprocess_images(\"datasets/pneumonia/\")\n",
    "save_preprocessed_data(pneumonia_data, pneumonia_labels, \"pneumonia\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: models/diabetes.pkl\n",
      "Model saved: models/heart.pkl\n",
      "Model saved: models/kidney.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def train_model(data_path, model_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Identify categorical columns and apply label encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    for column in df.select_dtypes(include=['object']).columns:  # For all categorical columns\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "    \n",
    "    X = df.iloc[:, :-1]  # Features (all columns except the last)\n",
    "    y = df.iloc[:, -1]   # Target (the last column)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Model saved: {model_path}\")\n",
    "\n",
    "# Train models\n",
    "train_model(\"datasets/diabetes.csv\", \"models/diabetes.pkl\")\n",
    "train_model(\"datasets/heart.csv\", \"models/heart.pkl\")\n",
    "train_model(\"datasets/kidney.csv\", \"models/kidney.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image-Based Disease Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Malaria Model...\n",
      "Found 56 images belonging to 2 classes.\n",
      "Found 14 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 672ms/step - accuracy: 0.5685 - loss: 1.8852 - val_accuracy: 0.6429 - val_loss: 0.6628\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493ms/step - accuracy: 0.6171 - loss: 1.1418 - val_accuracy: 0.4286 - val_loss: 1.1553\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487ms/step - accuracy: 0.4841 - loss: 0.8698 - val_accuracy: 0.5714 - val_loss: 0.9147\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step - accuracy: 0.6101 - loss: 0.7522 - val_accuracy: 0.5714 - val_loss: 0.7189\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484ms/step - accuracy: 0.6622 - loss: 0.5767 - val_accuracy: 0.6429 - val_loss: 0.6267\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step - accuracy: 0.9196 - loss: 0.4435 - val_accuracy: 0.5000 - val_loss: 0.6382\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - accuracy: 0.9028 - loss: 0.3724 - val_accuracy: 0.7857 - val_loss: 0.5807\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - accuracy: 0.8854 - loss: 0.3103 - val_accuracy: 0.5000 - val_loss: 0.6147\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step - accuracy: 0.9266 - loss: 0.2590 - val_accuracy: 0.6429 - val_loss: 0.5706\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492ms/step - accuracy: 0.9762 - loss: 0.1742 - val_accuracy: 0.7857 - val_loss: 0.5265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malaria model saved as 'malaria.h5'\n",
      "Training Pneumonia Model...\n",
      "Found 56 images belonging to 1 classes.\n",
      "Found 13 images belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 663ms/step - accuracy: 1.0000 - loss: 0.4563 - val_accuracy: 1.0000 - val_loss: 1.2024e-10\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step - accuracy: 1.0000 - loss: 1.6950e-10 - val_accuracy: 1.0000 - val_loss: 2.5280e-17\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 4.8219e-17 - val_accuracy: 1.0000 - val_loss: 6.0229e-23\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - accuracy: 1.0000 - loss: 5.5728e-25 - val_accuracy: 1.0000 - val_loss: 8.7187e-28\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - accuracy: 1.0000 - loss: 2.9985e-29 - val_accuracy: 1.0000 - val_loss: 6.0009e-32\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - accuracy: 1.0000 - loss: 5.7282e-31 - val_accuracy: 1.0000 - val_loss: 1.5371e-35\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step - accuracy: 1.0000 - loss: 1.8298e-34 - val_accuracy: 1.0000 - val_loss: 1.2618e-38\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia model saved as 'pneumonia.h5'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Set paths\n",
    "malaria_data_path = \"datasets/malaria\"\n",
    "pneumonia_data_path = \"datasets/pneumonia\"\n",
    "model_save_path = \"models\"\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# Define CNN model architecture\n",
    "def create_cnn_model(input_shape=(128, 128, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Prepare image data generators\n",
    "def prepare_data(data_path):\n",
    "    # Apply data augmentation and preprocessing\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    \n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',  # Binary classification (Infected/Uninfected)\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    return train_gen, val_gen\n",
    "\n",
    "# Train and save the malaria model\n",
    "def train_malaria_model():\n",
    "    print(\"Training Malaria Model...\")\n",
    "    malaria_train_gen, malaria_val_gen = prepare_data(malaria_data_path)\n",
    "    \n",
    "    model = create_cnn_model()\n",
    "    model.fit(malaria_train_gen, epochs=10, validation_data=malaria_val_gen)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model.save(os.path.join(model_save_path, \"malaria.h5\"))\n",
    "    print(\"Malaria model saved as 'malaria.h5'\")\n",
    "\n",
    "# Train and save the pneumonia model\n",
    "def train_pneumonia_model():\n",
    "    print(\"Training Pneumonia Model...\")\n",
    "    pneumonia_train_gen, pneumonia_val_gen = prepare_data(pneumonia_data_path)\n",
    "    \n",
    "    model = create_cnn_model()\n",
    "    model.fit(pneumonia_train_gen, epochs=10, validation_data=pneumonia_val_gen)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model.save(os.path.join(model_save_path, \"pneumonia.h5\"))\n",
    "    print(\"Pneumonia model saved as 'pneumonia.h5'\")\n",
    "\n",
    "# Main function to train both models\n",
    "def main():\n",
    "    train_malaria_model()\n",
    "    train_pneumonia_model()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment with Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2025-02-03 12:35:55.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.707 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.709 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.711 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.712 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.715 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.726 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.729 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:35:55.731 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Load structured data models\n",
    "diabetes_model = pickle.load(open(\"models/diabetes.pkl\", \"rb\"))\n",
    "heart_model = pickle.load(open(\"models/heart.pkl\", \"rb\"))\n",
    "kidney_model = pickle.load(open(\"models/kidney.pkl\", \"rb\"))\n",
    "\n",
    "# Load image-based models\n",
    "malaria_model = load_model(\"models/malaria.h5\")\n",
    "pneumonia_model = load_model(\"models/pneumonia.h5\")\n",
    "\n",
    "# Sidebar Navigation\n",
    "st.sidebar.title(\"Sireesha - Unified AI Multidisease Predictor\")\n",
    "option = st.sidebar.radio(\"Select a disease to predict:\", [\"Home\", \"Diabetes\", \"Heart Disease\", \"Kidney Disease\", \"Malaria\", \"Pneumonia\"])\n",
    "\n",
    "# Home Page\n",
    "if option == \"Home\":\n",
    "    st.title(\"Unified AI Multidisease Predictor\")\n",
    "    st.write(\"This web application allows you to predict multiple diseases using AI models.\")\n",
    "\n",
    "# Structured Data Prediction Function\n",
    "def predict_disease(model, user_input, feature_names):\n",
    "    df = pd.DataFrame([user_input], columns=feature_names)\n",
    "    prediction = model.predict(df)\n",
    "    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n",
    "\n",
    "# Image Prediction Function\n",
    "def predict_image(model, image):\n",
    "    image = image.resize((128, 128))\n",
    "    image = np.array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    prediction = model.predict(image)\n",
    "    return \"Positive\" if prediction[0] > 0.5 else \"Negative\"\n",
    "\n",
    "# Diabetes Prediction\n",
    "if option == \"Diabetes\":\n",
    "    st.title(\"Diabetes Prediction\")\n",
    "    pregnancies = st.number_input(\"Pregnancies\", min_value=0, max_value=20, value=1)\n",
    "    glucose = st.number_input(\"Glucose Level\", min_value=0, max_value=200, value=100)\n",
    "    blood_pressure = st.number_input(\"Blood Pressure\", min_value=0, max_value=200, value=70)\n",
    "    skin_thickness = st.number_input(\"Skin Thickness\", min_value=0, max_value=100, value=20)\n",
    "    insulin = st.number_input(\"Insulin Level\", min_value=0, max_value=800, value=80)\n",
    "    bmi = st.number_input(\"BMI\", min_value=0.0, max_value=50.0, value=25.0)\n",
    "    dpf = st.number_input(\"Diabetes Pedigree Function\", min_value=0.0, max_value=2.5, value=0.5)\n",
    "    age = st.number_input(\"Age\", min_value=0, max_value=120, value=30)\n",
    "    \n",
    "    if st.button(\"Predict Diabetes\"):\n",
    "        result = predict_disease(diabetes_model, [pregnancies, glucose, blood_pressure, skin_thickness, insulin, bmi, dpf, age], \n",
    "                                 [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"])\n",
    "        st.write(f\"Prediction: **{result}**\")\n",
    "\n",
    "# Heart Disease Prediction\n",
    "if option == \"Heart Disease\":\n",
    "    st.title(\"Heart Disease Prediction\")\n",
    "    age = st.number_input(\"Age\", min_value=20, max_value=100, value=50)\n",
    "    sex = st.selectbox(\"Sex\", [\"Male\", \"Female\"])\n",
    "    cp = st.selectbox(\"Chest Pain Type\", [0, 1, 2, 3])\n",
    "    trestbps = st.number_input(\"Resting Blood Pressure\", min_value=90, max_value=200, value=120)\n",
    "    chol = st.number_input(\"Cholesterol\", min_value=100, max_value=600, value=200)\n",
    "    \n",
    "    sex = 1 if sex == \"Male\" else 0\n",
    "\n",
    "    if st.button(\"Predict Heart Disease\"):\n",
    "        result = predict_disease(heart_model, [age, sex, cp, trestbps, chol], \n",
    "                                 [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\"])\n",
    "        st.write(f\"Prediction: **{result}**\")\n",
    "\n",
    "# Kidney Disease Prediction\n",
    "if option == \"Kidney Disease\":\n",
    "    st.title(\"Kidney Disease Prediction\")\n",
    "    rbc = st.selectbox(\"Red Blood Cells\", [\"Normal\", \"Abnormal\"])\n",
    "    pc = st.selectbox(\"Pus Cell\", [\"Normal\", \"Abnormal\"])\n",
    "    hemo = st.number_input(\"Hemoglobin\", min_value=0.0, max_value=20.0, value=12.0)\n",
    "    \n",
    "    rbc = 1 if rbc == \"Abnormal\" else 0\n",
    "    pc = 1 if pc == \"Abnormal\" else 0\n",
    "\n",
    "    if st.button(\"Predict Kidney Disease\"):\n",
    "        result = predict_disease(kidney_model, [rbc, pc, hemo], \n",
    "                                 [\"rbc\", \"pc\", \"hemo\"])\n",
    "        st.write(f\"Prediction: **{result}**\")\n",
    "\n",
    "# Malaria Prediction\n",
    "if option == \"Malaria\":\n",
    "    st.title(\"Malaria Detection\")\n",
    "    uploaded_file = st.file_uploader(\"Upload Blood Smear Image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "    if uploaded_file is not None:\n",
    "        image = Image.open(uploaded_file)\n",
    "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "        \n",
    "        if st.button(\"Predict Malaria\"):\n",
    "            result = predict_image(malaria_model, image)\n",
    "            st.write(f\"Prediction: **{result}**\")\n",
    "\n",
    "# Pneumonia Prediction\n",
    "if option == \"Pneumonia\":\n",
    "    st.title(\"Pneumonia Detection\")\n",
    "    uploaded_file = st.file_uploader(\"Upload Chest X-Ray Image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "    if uploaded_file is not None:\n",
    "        image = Image.open(uploaded_file)\n",
    "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "        \n",
    "        if st.button(\"Predict Pneumonia\"):\n",
    "            result = predict_image(pneumonia_model, image)\n",
    "            st.write(f\"Prediction: **{result}**\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_background(base64_str):\n",
    "    st.markdown(\n",
    "        f\"\"\"\n",
    "        <style>\n",
    "        .stApp {{\n",
    "            background-image: url(\"data:image/png;base64,{base64_str}\");\n",
    "            background-size: cover;\n",
    "        }}\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 12:45:14.163 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:45:14.164 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:45:14.166 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:45:14.167 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:45:14.168 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:45:14.169 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:45:14.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:45:14.171 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:45:14.171 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-03 12:45:14.172 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import base64\n",
    "\n",
    "# Function to encode the image file to base64\n",
    "def get_base64_image(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode()\n",
    "\n",
    "# Function to set the background image\n",
    "def set_background(encoded_image):\n",
    "    st.markdown(\n",
    "        f\"\"\"\n",
    "        <style>\n",
    "        .stApp {{\n",
    "            background-image: url('data:image/jpeg;base64,{encoded_image}');\n",
    "            background-size: cover;\n",
    "            background-position: center;\n",
    "            background-repeat: no-repeat;\n",
    "            height: 100vh;\n",
    "        }}\n",
    "        </style>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Homepage content\n",
    "def homepage():\n",
    "    # Set the absolute path to your image\n",
    "    image_path = r\"C:\\Users\\siree\\Desktop\\project 2\\statics\\doctor.jpg\"  # Use the correct absolute path\n",
    "    encoded_image = get_base64_image(image_path)\n",
    "    \n",
    "    # Set the background image\n",
    "    set_background(encoded_image)\n",
    "    \n",
    "    # Add content to the homepage\n",
    "    st.title(\"Welcome to the AI Multidisease Predictor\")\n",
    "    st.subheader(\"Powered by AI for Early Detection\")\n",
    "    \n",
    "    # Optional: Add additional content here (e.g., instructions, app description, etc.)\n",
    "    st.write(\n",
    "        \"Use this app to predict and detect diseases like Diabetes, Malaria, and Pneumonia using AI-powered models.\"\n",
    "    )\n",
    "\n",
    "# Call the homepage function to render the page\n",
    "if __name__ == \"__main__\":\n",
    "    homepage()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
